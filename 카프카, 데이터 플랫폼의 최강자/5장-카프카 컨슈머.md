# 5. 카프카 컨슈머
컨슈머 : 토픽에서 메시지를 가져와서 소비하는 역할을 하는 애플리케이션, 서버 등을 지칭.

다른 일반적인 메시지큐들과는 다르게 이미 가져온 메시지를 다시 가져올 수 있다.

## 5.1 컨슈머 주요 옵션
**컨슈머의 종류(주키퍼의 사용 유무)**
- 올드 컨슈머 : 컨슈머의 오프셋을 주키퍼의 지노드에 저장
- 뉴 컨슈머 : 컨슈머의 오프셋을 주키퍼가 아닌 카프카의 토픽에 저장

**카프카 컨슈머 옵션**
- bootstrap.servers : 카프카 클러스터에 처음 연결을 하기 위한 호스트와 포트 정보로 구정된 리스트 정보. 리스트 전체를 입력하는 방식이 권장됨(카프카 클러스터가 살아있음에도 접속이 불가능한 일이 없도록)
- fetch.min.bytes : 한번에 가져올 수 있는 최소 데이터 사이즈. 데이터가 누적될 때까지 기다린다.
- group.id : 컨슈머가 속한 컨슈머 그룹을 식별하는 식별자
- enable.auto.commit : 백그라운드로 주기적으로 오프셋을 커밋할지 말지 결정
- auto.offset.reset : 초기 오프셋이 없거나 현재 오프셋이 더이상 존재하지 않는 경우 다음 옵션으로 리셋
  - earliest : 가장 초기의 오프셋 값으로 설정
  - latest : 가장 마지막의 오프셋 값으로 설정
  - none : 이전 오프셋값을 찾지 못하면 에러유발
- fetch.max.bytes : 한번에 가져올 수 있는 최대 데이터 사이즈
- request.timeout.ms : 요청에 대해 응답을 기다리는 최대 시간
- session.timeout.ms : 컨슈머와 브로커사이의 세션타임아웃시간(default=10초). 만약 지정한 시간이 지나면 해당 컨슈머를 장애가 발생한 것으로 판단하여 컨슈머 그룹을 리밸런스한다.
하트비트 없이 얼마나 오랫동안 컨슈머가 있을 수 있는지를 제어
- heartbeat.interval.ms : 그룹 코디네이터에게 poll()메서드로 하트비트를 얼마나 자주 보낼것인지 조정함. 당연히 session.timeout.ms보다 낮아야함(보통 3분의 1로 설정. default=3초)
- max.poll.records : 단일 호출 poll()에 대한 최대 레코드 수를 조정
- max.poll.interval.ms : poll()로 하트비트만 보내고 실제론 메시지를 가져가지 않을수도 있다. 컨슈머가 무한정으로 파티션을 점유할 수 없도록 주기적으로 poll()을 호출하지 않으면 장애라고 판단함.
- auto.commit.interval.ms : 주기적으로 오프셋을 커밋하는 시간
- fetch.max.wait.ms : fetch.min.bytes에 의해 설정된 데이터보다 작은 경우 요청에 응답을 기다리는 최대 시간

## 5.2 콘솔 컨슈머로 메시지 가져오기
### 카프카 토픽 생성
```shell
./kafka-topics.sh --zookeeper 서버1:2181,서버2:2181,서버3:2181/지노드 --replication-factor 1 --partitions 1 --topic ksh-1 --create
```

### 카프카 메시지 프로듀스
```shell
./kafka-console-producer.sh --broker-list 서버1:9092,서버2:9092,서버3:9092 --topic ksh-1
```

### 카프카 메시지 컨슈밍
```shell
./kafka-console-consumer.sh --bootstrap-server 서버1:9092,서버2:9092,서버3:9092 --topic ksh-1 --from-beginning
```

만약 추가 옵션을 주지 않는다면 console-consumer-xxxxx로 컨슈머 그룹이 생성된다
### 카프카 컨슈머 그룹 리스트 조회
```shell
./kafka-consumer-groups.sh --bootstrap-server 서버1:9092,서버2:9092,서버3:9092 --list
```

그룹명은 아래와 같이 옵션으로 지정할 수 있다.
### 카프카 메시지 컨슈밍(컨슈머 그룹명 지정)
```shell
./kafka-console-consumer.sh --bootstrap-server 서버1:9092,서버2:9092,서버3:9092 --topic ksh-1 --group ksh-consumer-group-1 --from-beginning
```


## 5.3 자바와 파이썬을 이용한 컨슈머
```java
package org.example;

import java.util.List;
import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

public class Main {
	public static void main(String[] args) {
		Properties properties = new Properties();

		properties.put("bootstrap.servers", "서버1:9092,서버2:9092,서버3:9092");
		properties.put("group.id", "ksh-consumer-group-2");
		properties.put("enable.auto.commit", "true");
		properties.put("auto.offset.reset", "latest");
		properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		properties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
		consumer.subscribe(List.of("ksh-1"));
		
		// 자원을 직접 닫으면 컨슈머가 하트비트를 보내지 않아서 그룹 코디네이터가 해당 컨슈머가 종료된 것으로 감지하는 것보다 빠르게 진행되며 즉시 리밸런스가 발생한다.
		try (consumer) {

			while (true) {
				ConsumerRecords<String, String> records = consumer.poll(100);

				for (ConsumerRecord<String, String> record : records) {
					System.out.printf("Topic:%s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
						record.topic(), record.partition(), record.offset(), record.key(), record.value());
				}
			}

		}

	}
}
```

## 5.4 파티션과 메시지 순서
토픽의 파티션이 여러개일때 메시지 순서를 확인해보는 실습

### 1. 파티션 3개로 구성된 토픽 생성
```shell
./kafka-topics.sh --zookeeper 서버1:2181,서버2:2181,서버3:2181/comm-kafka --replication-factor 1 --partitions 3 --topic ksh-2 --create
```

### 2. 파티션 3개로 구성된 토픽에 메시지 전송
```shell
./kafka-console-producer.sh --broker-list 서버1:9092,서버2:9092,서버3:9092 --topic ksh-2
```
프롬프트가 나타나면 예시로 a부터 e까지 입력해보자

### 3. 토픽에서 메시지를 가져오고 순서를 확인해보자
```shell
./kafka-console-consumer.sh --bootstrap-server 서버1:9092,서버2:9092,서버3:9092 --topic ksh-2 --from-beginning
```

메시지 순서가 a~e 순서가 아닌 것을 확인할 수 있따.
토픽의 파티션끼리는 순서를 보장하지 않기 때문이다.

토픽의 파티션은 0번부터 시작하므로 0, 1, 2 3개의 파티션이 존재한다.
옵션을 주어 각 파티션별로 메시지를 가져와보자

### 4. 각 파티션별로 메시지 가져오자
```shell
./kafka-console-consumer.sh --bootstrap-server 서버1:9092,서버2:9092,서버3:9092 --topic ksh-2 --from-beginning --partition 0
./kafka-console-consumer.sh --bootstrap-server 서버1:9092,서버2:9092,서버3:9092 --topic ksh-2 --from-beginning --partition 1
./kafka-console-consumer.sh --bootstrap-server 서버1:9092,서버2:9092,서버3:9092 --topic ksh-2 --from-beginning --partition 2
```

파티션과 파티션 사이에서는 메시지 순서가 보장되지 않았으나
각 파티션 단위로의 메시지 순서는 지켜진 것을 확인할 수 있다.

토픽의 메시지 순서를 보장받기 위해서는 파티션 수를 1로 지정해서 사용해야 한다.

메시지 순서가 보장되어야 한다면 파티션 수를 하나로 하여 처리량이 떨어지는 부분을 감안하고 사용해야한다.

## 5.5 컨슈머 그룹
컨슈머는 카프카 토픽에서 메시지를 읽어오는 역할을 한다.
하나의 토픽에 여러 컨슈머 그룹이 동시에 접속해 메시지를 가져올 수 있다.

카프카는 동일한 토픽에 대해 여러 컨슈머가 메시지를 가져갈 수 있도록 컨슈머 그룹이라는 기능을 제공한다.

동일 컨슈머 그룹 내 컨슈머가 추가되면 각 컨슈머별로 파티션의 소유권이 재분배되는데 이를 리밸런스라고 한다.
리밸런스를 하는 동안 일시적으로 컨슈머는 메시지를 가져올 수 없다.

토픽의 파티션에는 하나의 컨슈머만 연결된다. 따라서 컨슈머그룹의 속도가 메시지생성 속도를 따라가지 못하는 경우 컨슈머만 늘리지말고 파티션도 그에 맞게 늘려줘야 한다.

컨슈머 그룹은 각자의 오프셋을 별도로 관리하기 때문에 하나의 토픽에 여러개의 컨슈머 그룹이 연결되어도 다른 컨슈머 그룹에 영향 없이 메시지를 가져갈 수 있다.
이 때 컨슈머 그룹 아이디는 서로 중복되지 않게 해야한다.

## 5.6 커밋과 오프셋
각 파티션에 대해 현재 위치를 업데이트하는 동작을 커밋한다고 한다.

### 5.6.1 자동 커밋
enable.auto.commit=true 로 설정하면 컨슈머는 5초마다 마지막 poll()호출에서 오프셋을 커밋한다. 5초가 기본값이며 auto.commit.interval.ms옵션을 통해 조절가능하다.

5초 단위로 오프셋을 커밋하는 경우를 생각해보자.
컨슈머가 실행된지 9초만에 메시지를 처리하다가 컨슈머가 추가되어 리밸런스가 발생하면 오프셋은 5초에 한번 커밋되고 그 이후에 소비한 메시지 오프셋은 커밋되지 않아서 중복처리가 발생하게 된다.
중복제거를 위해 자동커밋의 시간을 줄일 수 있지만 중복처리를 완벽히 제거하는 것은 불가능하다.

### 5.6.2 수동 커밋
메시지 처리가 완료될 때까지 메시지를 가져온 것으로 간주되어서는 안되는 경우에 사용한다.

수동커밋의 경우에도 중복이 발생할 수 있다.

카프카는 적어도 한번 메시지 처리를 보장한다.

### 5.6.3 특정 파티션 할당
특정 파티션에서 메시지를 가져와야하는 경우 컨슈머에 파티션을 직접 할당할 수 있다.
```java
package org.example;

import java.util.List;
import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;

public class prac5_6 {
	public static void main(String[] args) {
		Properties properties = new Properties();

		properties.put("bootstrap.servers", "서버1:9092,서버2:9092,서버3:9092");
		properties.put("group.id", "ksh-consumer-group-2");
		properties.put("enable.auto.commit", "true");
		properties.put("auto.offset.reset", "latest");
		properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		properties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
		String topic = "ksh-2";

		TopicPartition partition0 = new TopicPartition(topic, 0);
		TopicPartition partition1 = new TopicPartition(topic, 1);

		// 컨슈머에 특정 파티션을 할당할 수 있다.
		consumer.assign(List.of(partition0, partition1));

		try (consumer) {

			while (true) {
				ConsumerRecords<String, String> records = consumer.poll(100);

				for (ConsumerRecord<String, String> record : records) {
					System.out.printf("Topic:%s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
						record.topic(), record.partition(), record.offset(), record.key(), record.value());
				}
			}

		}

	}
}
```

### 5.6.4 특정 오프셋부터 메시지 가져오기
중복처리등의 이유로 오프셋 관리를 수동으로 해야하는 케이스도 있다.
이때 seek()메서드를 사용하면 된다.
```java
package org.example;

import java.util.List;
import java.util.Properties;

import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;

public class prac5_6_1 {
	public static void main(String[] args) {
		Properties properties = new Properties();

		properties.put("bootstrap.servers", "서버1:9092,서버2:9092,서버3:9092");
		properties.put("group.id", "ksh-consumer-group-2");
		properties.put("enable.auto.commit", "true");
		properties.put("auto.offset.reset", "latest");
		properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
		properties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

		KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);
		String topic = "ksh-2";

		TopicPartition partition0 = new TopicPartition(topic, 0);
		TopicPartition partition1 = new TopicPartition(topic, 1);

		// 컨슈머에 특정 파티션을 할당할 수 있다.
		consumer.assign(List.of(partition0, partition1));

		// 각 파티션별로 가져올 오프셋 위치를 지정할 수 있다.
		consumer.seek(partition0, 3);
		consumer.seek(partition1, 5);

		try (consumer) {

			while (true) {
				ConsumerRecords<String, String> records = consumer.poll(100);

				for (ConsumerRecord<String, String> record : records) {
					System.out.printf("Topic:%s, Partition: %s, Offset: %d, Key: %s, Value: %s\n",
						record.topic(), record.partition(), record.offset(), record.key(), record.value());
				}
			}

		}

	}
}
```
### 5.7 정리
컨슈머
컨슈머그룹
컨슈머 주요 옵션
토픽과 파티션 
리밸런싱
...
