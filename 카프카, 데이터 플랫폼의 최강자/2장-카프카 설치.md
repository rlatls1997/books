# 2. 카프카 설치
카프카는 크게 프로듀서, 카프카(브로커), 컨슈머, 주키퍼로 분류할 수 있다.

주키퍼는 컨슈머와 통신하는 부분 외에도 카프카와 직접 통신하면서,
카프카의 메타데이터 정보를 주키퍼에 저장하고 카프카의 상태관리 등의 목적으로 이용됨.

## 2.1 카프카 관리를 위한 주키퍼
주키퍼는 분산 애플리케이션 관리를 위한 코디네이션 시스템.
분산 애플리케이션이 안정적인 서비스를 할 수 있도록 분산되어있는 각 애플리케이션의 정보를 중앙에 집중하고 구성 관리, 그룹 관리 네이밍, 동기화 등의 서비스를 제공

주키퍼는 서버 여러 대를 앙상블(클러스터)로 구성하고, 
분산 애플리케이션들이 각각 클라이언트가 되어 주키퍼 서버들과 커넥션을 맺은 후 상태정보등을 주고받는다.

상태정보들은 주키퍼의 `지노드`라 불리는 곳에 키-값 형태로 저장.
지노드에 키-값이 저장된 것을 이용하여 분산 애플리케이션들은 서로 데이터를 주고 받는다.

`지노드` : 주키퍼에서 데이터를 저장하기 위한 공간의 이름. 지노드에 저장하는 데이터크기는 킬로바이트 수준으로 매우 작다.

주키퍼의 각 지노드는 데이터 변경 등에 대한 유효성 검사등을 위해 버전 번호를 관리하게 되며, 지노드의 데이터가 변경될 때마다 지노드의 버전 번호가 증가한다.

주키퍼에 저장되는 데이터는 모두 메모리에 저장되어 처치량이 크고 속도가 빠르다.

주키퍼는 신뢰성 있는 서비스를 위해 앙상블(클러스터)이라는 호스트 세트를 구성할 수 있다. 앙상블로 구성되어 있는 주키퍼는 과반수 방식에 따라 살아 있는 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능하다.

과반만 되면 서비스가 가능하므로 앙상블 구성 숫자가 많을수록 많은 노드에서 장애가 발생하더라도 서비스를 계속 제공할 수 있고 성능적인 효과도 얻을 수 있다.(5대 이상으로 앙상블을 구성한 경우 초당 약 14만개의 요청 처리)



## 2.2 주키퍼 설치
peter-zk001, peter-zk002, peter-zk003 라고 명명한 3대의 주키퍼 설치 예

주키퍼는 자바 애플리케이션이기 때문에 서버에 자바가 설치되어 있어야 한다.

### 1. 주키퍼 다운로드
zookeeper.apache.org에서 미러사이트 찾고 wget으로 다운로드.
```shell
wget http://apache/mirror.cdnetworks.com/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz
```

- 압축해제
```shell
tar zxf zookeeper-3.4.10.tar.gz
```

버전변경 등 관리를 위해 심볼릭 링크를 설정해 사용하는것이 좋다
- 심볼릭 링크 생성
```shell
ln -s zookeeper-3.4.10.zookeeper
```
- 심볼릭 링크 생성 확인
```shell
ls -la zookeeper
```

주키퍼는 애플리케이션에서 별도의 데이터 디렉토리를 사용한다.
이 디렉토리에는 지노드의 복사본인 스냅샷과 트랜잭션 로그들이 저장된다.

트랜잭션 로그 : 지노드에 변경사항이 발생하면 트랜잭션 로그에 추가되고 로그가 어느정도 커지면 현재 모든 지노드의 상태 스냅샷이 파일시스템에 저장된다.
중요한 디렉터리이기 때문에 설치경로와 다른 경로로 설정하는것이 좋다.

/data경로로 설정해보자.
- data디렉터리 생성
```shell
mkdir -p /data 
#p옵션은 뭐임?
```

앙상블 내에서 주키퍼 노드를 구분하기 위한 id를 만들어야 한다.
주키퍼에서는 myid라고 부르며 정수 형태로 만들어주면 된다.

/data 디렉터리 하단에 myid라는 파일을 만들고 id값을 넣어준다.
이 파일은 주키퍼 설정파일에서 사용된다.
- myid파일 생성
```shell
echo 1 > /data/myid

#다른 서버에도 동일하게 만들어준다
echo 2 > /data/myid
echo 3 > /data/myid
```

다음으로 주키퍼의 환경설정 파일을 만들어야한다.
주키퍼의 환경설정 파일 이름은 zoo.cfg이다
- 주키퍼 환경설정파일 zoo.cfg 만들기
```shell
vi /usr/local/zookeeper/conf/zoo.cfg
```
```shell
tickTime=2000 # 주키퍼가 사용하는 시간에 대한 기본 측정 단위(밀리초)
initLimit=10 # 팔로워가 리더와 초기에 연결하는 시간에 대한 타임 아웃 tick의 수 (이러면 20초인가?)
syncLimit=5 # 팔로워가 리더와 동기화 하는 시간에 대한 타임 아웃 tick의 수(주피커에 저장된 데이터가 크면 수를 늘려야함)
dataDir=/data # 주키퍼의 트랜잭션 로그와 스냅샷이 저장되는 데이터 저장 경로(위에서 만든 directory)
clientPort=2181 # 주키퍼 사용 TCP포트
server.1=peter-zk001:2888:3888 # 주키퍼 앙상불 구성을 위한 서버 설정. server.myid 형식으로 사용
server.2=peter-zk002:2888:3888
server.3=peter-zk003:2888:3888
```

2888, 3888은 기본 포트이며 앙상블 내 노드끼리 연결하는데 사용하고 리더 선출에 사용한다.
주키퍼의 동시 연결제한, 세션 타임아웃 관리, 보관하는 스냅샷 수 등 상세 설정도 있음. 문서 참고

### 2. 주키퍼 실행
- 주키퍼 실행 명령
```shell
/usr/local/zookeeper/bin/zkServer.sh start
```

- 주키퍼 중지 명령
```shell
/user/local/zookeeper/bin/zkServer.sh stop
```

주키퍼 프로세스를 효율적으로 관리하기 위해 systemd에 등록해서 운영할 수 있다.
주키퍼를 systemd에 등록하기 위해 주키퍼용 systemd파일을 만들어야 한다.
- 주키퍼용 systemd파일 생성
```shell
vi /etc/systemd/system/zookeeper-server.service
```
```shell
[Unit] # 일반적인 옵션을 나타냄. 실행순서를 조정하는 옵션을 주로 사용(After, Before)
Description=zookeeper-server # 해당 유닛에 대한 상세 설명. systemctl status명령에서 표시됨
After=network.target # 유닛이 시작되는 순서를 조정하여 After에 지정된 유닛이 실행된 이후 시작된다.

[Service] # 서비스 실행과 관련된 옵션
Type=forking # ExecStart에 영향을 주는 유닛 프로세스가 시작됨
User=root
Group=root
SyslogIdentifier=zookeeper-server # syslog에서 구분하기 위한 이름
WorkingDirectory=/usr/local/zookeeper # 실행된 프로세스의 작업 디렉토리를 설정
Restart=always # always인 경우 systemctl명령어로 인한 중지가 아니라면 프로세스가 종료된 후 항상 재시작함
RestartSec=0s # Restart옵션과 연결되어 몇 초에 실행할지를 정함
ExecStart=/usr/local/zookeeper/bin/zkServer.sh start # 서비스가 시작될 때 실행할 명령어
ExecStop=/usr/local/zookeeper/bin/zkServer.sh stop # 서비스가 중지될 때 실행할 명령어
```

systemd의 파일을 새로 만들거나 수정한 이후에는 반드시 systemd 재시작을 해야함
- systemd재시작
```shell
systemctl daemon-reload
```

준비한 모든 주키퍼 서버에 systemd설정까지 했다면 각 서버에서 주키퍼를 시작하면 된다.
- 주키퍼 프로세스 시작
```shell
systemctl start zookeeper-server.service

# 중지
systemctl stop zookeeper-server.service
# 재시작
systemctl restart zookeeper-server.service
```

옵션을 통해 서버가 부팅될때 주키퍼 프로세스를 자동으로 실행할 수도 있다
- 서버가 부팅될 때 자동 실행되도록 설정
```shell
# 자동실행되도록 설정
systemctl enable zookeeper-server.service

# 자동실행 안되도록 설정
systemctl disable zookeeper-server.service
```

- 주키퍼가 정상적으로 실행되었는지 확인하기
```shell
systemctl status zookeeper-server.service
```

## 2.3 카프카 설치
카프카 클러스터를 구성하는 서버 대수는 주키퍼와 다르게 과반수 운영을 위해 홀수로 구성할 필요가 없다.
자유롭게 구성하면 되고 예로 브로커 3대로 클러스터를 구성해보자

주키퍼는 과반이 다운되면 서비스를 하지 못하는 반면 카프카는 과반이 다운되어도 서비스를 할 수 있다.
되도록 카프카와 주키퍼는 별도의 서버에 구성하자.

예시로 peter-kafka001, peter-kafka002, peter-kafka003 3대로 카프카 클러스터를 구성해보자

### 1. 카프카 다운로드
kafka.apache.org/downloads
카프카또한 JVM에서 실행되므로 서버에 자바가 설치되어 있어야 한다.

- 원하는 경로로 이동 후 wget으로 다운로드
```shell
wget http://apache.mirror.cdnetworks.com/kafka/~~~~
```

- 압축해제
```shell
tar zxf kafka_버전.tgz
```

- 심볼릭 링크 생성
```shell
ln -s kafka_버전 kafka

# 심볼릭 링크 확인
ls -la kafka
```

### 2. 카프카 환경설정
카프카 환경설정에 필요한 정보인 서버별 브로커 아이디, 카프카 저장 디렉토리, 주키퍼 정보 등을 정하고 정보를 수정해야 한다.
브로커id는 다음과 같이 정해보자
peter-kafka001 -> broker.id=1
peter-kafka002 -> broker.id=2
peter-kafka003 -> broker.id=3

카프카에서 사용할 저장 디렉토리도 준비해야한다.
카프카는 일반 메시징 서비스들과 달리 저장된 데이터를 임시로 보관하는 기능이 있다.

디스크가 여러개로 수정된 서버인 경우 디스크의 수만큼 디렉터리를 만들어줘야 각 디스트별로 I/O를 분산할 수 있다.
저장 디렉터리를 2개로 설정해보자
- 저장 디렉터리 생성
```shell
# 3대의 서버에 동일하게 생성한다
mkdir -p /data1
mkdir -p /data2
```

다음으로 카프카가 바라보는 주키퍼의 정보를 어떻게 해야할지 결정해야한다.
-> 결론은 주키퍼 정보를 입력할 때에는 주키퍼 앙상블 서버 리스트를 모두 입력해야한다.
`zookeeper.connect=peter-zk001:2181,peter-zk002:2181,peter-zk003:2181`

위와 같이 주키퍼 상상블의 호스트 이름과 포트 정보만 입력하면 주키퍼 지노드의 최상위 경로를 사용하게 된다.
최상위 경로를 사용하게 되면 하나의 주키퍼 앙상블 세트와 하나의 애플리케이션만 사용할 수 있게 된다.

`지노드를 구분해서 사용하면 하나의 주키퍼 앙상블 세트를 여러 개의 애플리케이션에서 공용으로 사용할 수 있다!!`

지노드를 구분해서 사용하는 경우에는 호스트, 포트정보 뒤에 지노드 이름을 추가 입력하면 된다.
`zookeeper.connect=peter-zk001:2181,peter-zk002:2181,peter-zk003:2181/peter-kafka01`
`zookeeper.connect=peter-zk001:2181,peter-zk002:2181,peter-zk003:2181/peter-kafka02`
이렇게 나누던

`zookeeper.connect=peter-zk001:2181,peter-zk002:2181,peter-zk003:2181/peter-kafka/01`
`zookeeper.connect=peter-zk001:2181,peter-zk002:2181,peter-zk003:2181/peter-kafka/02`
이렇게 나누던
(개인적으로 같은 역할을 하는 클러스터끼리 지노드를 나누고 그 하위에서 또 나누는 것이 정돈된 느낌이다.)

선호하는 방법을 선택해서 사용하면 된다.

이제 환경설정 파일 수정 준비는 끝났으니 수정을 하면 된다
- 환경설정 파일 열기
```shell
vi /usr/local/kafka/config/server.properties
```
```shell
...
# 준비한 브로커 아이디를 기입한다. 예로 peter-kafka001에서는 1, 2에서는 2..
broker.id=0
...
중략
...
# 디렉터리 경로이다. 예제와 같이 디스크 구성이 여러개인 경우 log.dirs=/data1,/data2 처럼 여러개 기입할 수 있다. 
log.dirs=/tmp/kafka-logs
...
중략
...
# 주키퍼 정보를 수정한다. 별도의 지노드를 사용하는 경우 브로커가 시작될 때 해당 지노드에 주키퍼가 없다면 자동으로 지노드를 생성한다.
# zookeeper.connect=peter-zk001:2181,peter-zk002:2181,peter-zk003:2181/peter-kafka
zookeeper.connect=localhost:2181
...
```

**카프카 주요 옵션**
- broker.id : 브로커를 구분하기 위한 id
- delete.topic.enable : 토픽 삭제 기능을 on/off
- default.replication.factor : 리플리케이션 팩터 옵션을 주지 않았을 경우의 기본값
- min.insync.replicas : 최소 리플리케이션 팩터
- auto.create.topics.enable : 존재하지 않는 토픽으로 퍼블리셔가 메시지를 보냈을 때 자동으로 토픽생성
- offsets.topic.num.partitions : offsets토픽의 파티션 수
- offsets.topic.replication.factor : offsets 토픽의 리플레케이션 팩터
- num.partitions : 파티션 수 옵션을 주징 ㅏㄶ았을 경우의 기본값
- log.retentions.hours : 저장된 로그의 보관 주기
- log.segment.bytes : 저장되는 로그 파일 하나의 크기
- message.max.bytes : 카프카에서 허용하는 가장 큰 메시지 크기
- log.flush.interval.ms : 메시지가 디스크로 플러시되기 전 메모리에 유지하는 시간
- log.flush.interval.messages : 메시지가 디스크로 플러시되기 전 누적 메시지 수

그 외 옵션 문서 참고
`환경설정 변경 후 변경내용이 적용되려면 반드시 카프카 클러스터를 재시작해야한다`


### 3. 카프카 실행
시작 명령어와 함께 카프카 환경 설정 파일을 옵션으로 주어 실행하면 된다.
- 카프카 실행
```shell
/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties

# 백그라운드로 실행하려면 -deamon옵션을 주면 된다.
/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties -deamon

# 중지
/usr/local/kafka/bin/kafka-server-stop.sh
```

카프카도 운영 편의성을 위해 systemd에 등록하자
- 카프카 systemd 파일 생성
```shell
vi /etc/systemd/system/kafka-server.service
```
```shell
[Unit] # 일반적인 옵션을 나타냄. 실행순서를 조정하는 옵션을 주로 사용(After, Before)
Description=kafka-server # 해당 유닛에 대한 상세 설명. systemctl status명령에서 표시됨
After=network.target # 유닛이 시작되는 순서를 조정하여 After에 지정된 유닛이 실행된 이후 시작된다.

[Service] # 서비스 실행과 관련된 옵션
Type=simple # ExecStart에 영향을 주는 유닛 프로세스가 시작됨
User=root
Group=root
SyslogIdentifier=kafka-server # syslog에서 구분하기 위한 이름
WorkingDirectory=/usr/local/kafka # 실행된 프로세스의 작업 디렉토리를 설정
Restart=no # always인 경우 systemctl명령어로 인한 중지가 아니라면 프로세스가 종료된 후 항상 재시작함
RestartSec=0s # Restart옵션과 연결되어 몇 초에 실행할지를 정함
ExecStart=/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties # 서비스가 시작될 때 실행할 명령어
ExecStop=/usr/local/kafka/bin/kafka-server-stop.sh # 서비스가 중지될 때 실행할 명령어
```
systemd의 파일을 새로 만들거나 기존 파일을 수정한 이후에는 반드시 systemd 재시작을 해야한다
```shell
systemctl daemon-reload
```

systemd설정까지 했다면 3대의 서버에서 동시에 시작 명령을 하자
```shell
systemstl start kafka-server.service

# 상태정보확인
systemctl status kafka-server.service
```


## 2.4 카프카 상태 확인
### 1. TCP포트 확인
주키퍼의 기본 TCP포트는 2181이고 카프카의 기본 TCP포트는 9092이다.
주키퍼 서버에서 TCP 2181포트가 리스닝 상태인지 확인해보자

- n : 이름이 아닌 숫자로 표시
- t : tcp
- l : 리스닝 상태 표시
- p : pid와 프로그램 표시
- 주키퍼 포트 상태 확인
```shell
nestat -ntlp : grep 2181
```

- 카프카 포트 상태 확인
```shell
nestat -ntlp : grep 9092
```

LISTEN이 뜨는지 확인하자

### 2. 주키퍼 지노드를 이용한 카프카 정보 확인
주키퍼에서는 CLI로 진입하기 위한 명령어를 제공한다
- 주키퍼 CLI 진입
```shell
/usr/local/zookeeper/bin/zkCli.sh
```

- ls명령어를 이용하여 peter-kafka라는 지노드가 있는지 확인하기
```shell
ls /

# 출력
[zookeeper, peter-kafka]
```

주키퍼 지노드에서 카프카 클러스터 서버 3대가 모두 잘 연결되었는지 확인해보자
해당 지노드 디렉터리에서 리스트를 확인할 수 있다.
- 지노드에서 카프카 클러스터의 브로커 id 확인하기
```shell
ls /peter-kafka/brokers/ids

# 출력
[1, 2, 3]
```

## 2.5 카프카 시작하기
명령어를 통해 카프카가 제대로 동작하는지 확인해보자

### 1. 카프카 토픽 생성
토픽 생성은 옵션에 주키퍼 정보를 추가하고 토픽이름을 추가하여 만들 수 있다
- 토픽 생성
```shell
/usr/local/kafka/bin/kafka-topics.sh
--zookeeper peter-zk001:2181,peter-zk002:2181,peter-zk003:2181/peter-kafka
--replication-factor 1
--partitions 1
--topic peter-topic
--create

# 출력
# Created topic "peter-topic".
```

토픽을 삭제하려면 브로커 환경설정에서 delete.topic.enable=true로 설정되어 있어야 한다
- 토픽 삭제
```shell
/usr/local/kafka/bin/kafka-topics.sh
--zookeeper peter-zk001:2181,peter-zk002:2181,peter-zk003:2181/peter-kafka
--topic peter-topic
--delete
```

메시지를 퍼플리싱해보자
- 카프카 메시지 생성
```shell
/usr/local/kafka/bin/kafka-console-producer.sh
--broker-list peter-kafka001:9092,peter-kafka002:9092,peter-kafka003:9092
--topic peter-topic

# 위 명령어를 입력하면 >프롬프트와 함께 입력창이 나타난다. 메시지를 입력하고 enter누르면 토픽에 메시지가 생성된다
> message1
> message2
```

메시지를 소비해보자
- 카프카 메시지 소비
```shell
/usr/local/kafka/bin/kafka-console-consumer.sh
--bootstrap-server peter-kafka001:9092,peter-kafka002:9092,peter-kafka003:9092
--topic peter-topic
--from-beginning

# 출력
# message1
# message2
```
